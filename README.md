# Outstanding AI Papers - A Review ⭐️

The most significant AI research papers are listed in this collection and are organized by publication date. We update this work frequently, so if you have any recommendations for compelling papers, we'd be delighted to consider them. Feel free to give this repository a star if you enjoy the work.

Maintainer: [Aimerou Ndiaye](https://github.com/aimerou)

Twitter: [Twitter Account](https://twitter.com/AmrouNdiaye1)

----

## All Time Papers
* 1958: [The perceptron: A probabilistic model for information storage and organization in the brain (Perceptron)](https://psycnet.apa.org/record/1959-09865-001)
* 1975: [Cognitron: A self-organizing multilayered neural network (MLP)](https://link.springer.com/article/10.1007/BF00342633)
* 1984: [Classification and Regression Trees (CART)](https://www.taylorfrancis.com/books/mono/10.1201/9781315139470/classification-regression-trees-leo-breiman)
* 1986: [Learning representations by back-propagating errors (Backpropagation)](https://www.nature.com/articles/323533a0)
* 1989: [A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition (HMM)](https://ieeexplore.ieee.org/abstract/document/18626)
* 1997: [A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting (Adaboost)](https://www.sciencedirect.com/science/article/pii/S002200009791504X)
* 1998: [Gradient-based learning applied to document recognition (CNN/GTN)](https://ieeexplore.ieee.org/abstract/document/726791)
* 2012: [ImageNet Classification with Deep Convolutional Neural Networks (AlexNet)](https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html)
* 2013: [Efficient Estimation of Word Representations in Vector Space (Word2vec)](https://arxiv.org/abs/1301.3781)
* 2014: [Generative Adversarial Networks (GAN)](https://papers.nips.cc/paper/2014/hash/5ca3e9b122f61f8f06494c97b1afccf3-Abstract.html)
* 2014: [Adam: A Method for Stochastic Optimization (Adam)](https://arxiv.org/abs/1412.6980)
* 2015: [Human-level control through deep reinforcement learning (Deep Q Network)](https://www.nature.com/articles/nature14236/)
* 2015: [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (Faster R-CNN)](https://papers.nips.cc/paper/2015/hash/14bfa6bb14875e45bba028a21ed38046-Abstract.html)
* 2017: [Attention is All you Need (Transformer)](https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html)
* 2020: [Language Models are Few-Shot Learners (GPT-3)](https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html)
* 2020: [Denoising Diffusion Probabilistic Models (DDPM)](https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html)
* 2021: [Highly accurate protein structure prediction with AlphaFold (Alphafold)](https://www.nature.com/articles/s41586-021-03819-2)
* 2022: [ChatGPT: Optimizing Language Models For Dialogue](https://openai.com/blog/chatgpt/)

## 2022 Papers
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)

## 2023 Papers
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
* DD/MM: [Title of the article](https://arxiv.org/abs/...)
