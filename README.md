# Top AI Papers - A Review ⭐️

The most significant AI papers since 2022 are listed in this collection and are organized by publication date. This repository covers five fields : natural language processing (NLP), computer vision, multimodal learning, audio processing and reinforcement learning. Papers are primarily ranked by number of citations and subjectively by their degree of innovation in the field. If you have any recommendations for compelling papers, we'd be delighted to consider them. Feel free to give this repository a star if you enjoy the work.

Maintainer: [Aimerou Ndiaye](https://github.com/aimerou)

Twitter: [Twitter Account](https://twitter.com/AmrouNdiaye1)

## Taxonomy
To select the most relevant papers, we chose subjective limits in terms of number of citations. Each icon here designates a paper type that meets one of these criteria.

:fire: (Historical Paper): more than 10k citations and a decisive impact in the evolution of AI.

:star2: (Important Paper): more than 50 citations and state of the art results.

:arrow_double_up: (Trend): 5 to 50 citations, innovative contribution and growing adoption.

:newspaper: (Important Article): decisive work that was not accompanied by a research paper.

----

## Historical Papers
* 1958: [Perceptron: A probabilistic model for information storage and organization in the brain (Perceptron) :fire:](https://psycnet.apa.org/record/1959-09865-001)
* 1986: [Learning representations by back-propagating errors (Backpropagation) :fire:](https://www.nature.com/articles/323533a0)
* 1989: [A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition (HMM) :fire:](https://ieeexplore.ieee.org/abstract/document/18626)
* 1992: [A training algorithm for optimal margin classifiers (SVM) :fire:](https://dl.acm.org/doi/10.1145/130385.130401)
* 1997: [A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting (Adaboost) :fire:](https://www.sciencedirect.com/science/article/pii/S002200009791504X)
* 1998: [Gradient-based learning applied to document recognition (CNN/GTN) :fire:](https://ieeexplore.ieee.org/abstract/document/726791)
* 2012: [ImageNet Classification with Deep Convolutional Neural Networks (AlexNet) :fire:](https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html)
* 2013: [Efficient Estimation of Word Representations in Vector Space (Word2vec) :fire:](https://arxiv.org/abs/1301.3781)
* 2014: [Generative Adversarial Networks (GAN) :fire:](https://papers.nips.cc/paper/2014/hash/5ca3e9b122f61f8f06494c97b1afccf3-Abstract.html)
* 2014: [Adam: A Method for Stochastic Optimization (Adam) :fire:](https://arxiv.org/abs/1412.6980)
* 2015: [Human-level control through deep reinforcement learning (Deep Q Network) :fire:](https://www.nature.com/articles/nature14236/)
* 2015: [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (Faster R-CNN) :fire:](https://papers.nips.cc/paper/2015/hash/14bfa6bb14875e45bba028a21ed38046-Abstract.html)
* 2015: [U-Net: Convolutional Networks for Biomedical Image Segmentation (U-Net) :fire:](https://arxiv.org/abs/1505.04597)
* 2015: [Deep Residual Learning for Image Recognition (ResNet) :fire:](https://arxiv.org/abs/1512.03385)
* 2017: [Attention is All you Need (Transformer) :fire:](https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html)
* 2018: [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (BERT) :fire:](https://arxiv.org/abs/1810.04805)
* 2020: [Language Models are Few-Shot Learners (GPT-3) :fire:](https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html)
* 2021: [Highly accurate protein structure prediction with AlphaFold (Alphafold) :fire:](https://www.nature.com/articles/s41586-021-03819-2)
* 2022: [ChatGPT: Optimizing Language Models For Dialogue (ChatGPT) :newspaper:](https://openai.com/blog/chatgpt/)

## NLP
* 01/2022: [LaMBDA: Language Models for Dialog Applications (LaMBDA)](https://arxiv.org/abs/2201.08239)
* 01/2022: [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models (CoT)](https://arxiv.org/abs/2201.11903)
* 02/2022: [Competition-Level Code Generation with AlphaCode (AlphaCode)](https://www.science.org/doi/full/10.1126/science.abq1158)
* 02/2022: [Finetuned Language Models Are Zero-Shot Learners (FLAN)](https://arxiv.org/abs/2109.01652)
* 02/2022: [Transformer Memory as a Differentiable Search Index (DSI)](https://arxiv.org/abs/2202.06991)
* 03/2022: [Training language models to follow human instructions with human feedback (InstructGPT)](https://arxiv.org/abs/2203.02155)
* 03/2022: [Multitask Prompted Training Enables Zero-Shot Task Generalization (T0)](https://arxiv.org/abs/2110.08207)
* 03/2022: [Training Compute-Optimal Large Language Models (Chinchilla)](https://arxiv.org/abs/2203.15556)
* 04/2022: [PaLM: Scaling Language Modeling with Pathways (PaLM)](https://arxiv.org/abs/2204.02311)
* 06/2022: [Beyond the Imitation Game: Quantifying and extrapolating the capabilities of lang... (BIG-bench)](https://arxiv.org/abs/2206.04615)
* 06/2022: [Solving Quantitative Reasoning Problems with Language Models (Minerva)](https://arxiv.org/abs/2206.14858)
* 07/2022: [No Language Left Behind: Scaling Human-Centered Machine Translation (NLLB-200)](https://arxiv.org/abs/2207.04672)
* 10/2022: [Language Models are Multilingual Chain-of-Thought Reasoners (mCoT)](https://arxiv.org/abs/2210.03057)
* 10/2022: [ReAct: Synergizing Reasoning and Acting in Language Models (ReAct)](https://arxiv.org/abs/2210.03629)
* 11/2022: [BLOOM: A 176B-Parameter Open-Access Multilingual Language Model (BLOOM)](https://arxiv.org/abs/2211.05100)
* 11/2022: [Optimizing Language Models for Dialogue (ChatGPT)](https://openai.com/blog/chatgpt/)
* 12/2022: [Constitutional AI: Harmless from AI Feedback (Harmless Assistant)](https://arxiv.org/abs/2212.08073)
* 01/2023: [DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature (DetectGPT)](https://arxiv.org/abs/2301.11305)
* 02/2023: [Multimodal Chain-of-Thought Reasoning in Language Models (Multimodal-CoT)](https://arxiv.org/abs/2302.00923)
* 02/2023: [Toolformer: Language Models Can Teach Themselves to Use Tools (Toolformer)](https://arxiv.org/abs/2302.04761)
* 02/2023: [The Wisdom of Hindsight Makes Language Models Better Instruction Followers (HIR)](https://arxiv.org/abs/2302.05206)
* 02/2023: [LLaMA: Open and Efficient Foundation Language Models (LLaMA)](https://arxiv.org/abs/2302.13971)
* 03/2023: [GPT-4](https://openai.com/research/gpt-4)
* 03/2023: [Sparks of Artificial General Intelligence: Early experiments with GPT-4 (GPT-4 Eval)](https://arxiv.org/abs/2303.12712)
* 03/2023: [HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace (HuggingGPT)](https://arxiv.org/abs/2303.17580)
* 04/2023: [Generative Agents: Interactive Simulacra of Human Behavior (Generative Agents)](https://arxiv.org/abs/2304.03442)

## Computer Vision
* 01/2022: [A ConvNet for the 2020s (ConvNeXt)](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_A_ConvNet_for_the_2020s_CVPR_2022_paper.html)
* 01/2022: [Patches Are All You Need (ConvMixer)](https://arxiv.org/abs/2201.09792)
* 02/2022: [Block-NeRF: Scalable Large Scene Neural View Synthesis (Block-NeRF)](https://openaccess.thecvf.com/content/CVPR2022/html/Tancik_Block-NeRF_Scalable_Large_Scene_Neural_View_Synthesis_CVPR_2022_paper.html)
* 03/2022: [DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection (DINO)](https://openreview.net/forum?id=3mRwyG5one)
* 03/2022: [Scaling Up Your Kernels to 31×31: Revisiting Large Kernel Design in CNNs (Large Kernel CNN)](https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Scaling_Up_Your_Kernels_to_31x31_Revisiting_Large_Kernel_Design_CVPR_2022_paper.html)
* 03/2022: [TensoRF: Tensorial Radiance Fields (TensoRF)](https://link.springer.com/chapter/10.1007/978-3-031-19824-3_20)
* 04/2022: [Hierarchical Text-Conditional Image Generation with CLIP Latents (DALL-E 2)](https://arxiv.org/abs/2204.06125)
* 05/2022: [Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding (Imagen)](https://arxiv.org/abs/2205.11487)
* 05/2022: [GIT: A Generative Image-to-text Transformer for Vision and Language (GIT)](https://arxiv.org/abs/2205.14100)
* 06/2022: [CMT: Convolutional Neural Network Meet Vision Transformers (CMT)](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_CMT_Convolutional_Neural_Networks_Meet_Vision_Transformers_CVPR_2022_paper.html)
* 08/2022: [Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation (DreamBooth)](https://arxiv.org/abs/2208.12242)
* 09/2022: [DreamFusion: Text-to-3D using 2D Diffusion (DreamFusion)](https://arxiv.org/abs/2209.14988)
* 09/2022: [Make-A-Video: Text-to-Video Generation without Text-Video Data (Make-A-Video)](https://arxiv.org/abs/2209.14792)
* 10/2022: [LAION-5B: An open large-scale dataset for training next generation image-text models (LAION-5B)](https://arxiv.org/abs/2210.08402)
* 11/2022: [InstructPix2Pix: Learning to Follow Image Editing Instructions (InstructPix2Pix)](https://arxiv.org/abs/2211.09800)
* 11/2022: [InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Conv... (InternImage)](https://arxiv.org/abs/2211.05778v3)
* 12/2022: [Scalable Diffusion Models with Transformers (DiT)](https://arxiv.org/abs/2212.09748)
* 01/2023: [Muse: Text-To-Image Generation via Masked Generative Transformers (Muse)](https://arxiv.org/abs/2301.00704)
* 01/2023: [StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale Text-to-Image Synthesis (StyleGAN-T)](https://arxiv.org/abs/2301.09515)
* 02/2023: [Scaling Vision Transformers to 22 Billion Parameters (ViT 22B)](https://arxiv.org/abs/2302.05442)
* 02/2023: [Adding Conditional Control to Text-to-Image Diffusion Models (ControlNet)](https://arxiv.org/abs/2302.05543)
* 03/2023: [Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models (Visual ChatGPT)](https://arxiv.org/abs/2303.04671)
* 03/2023: [Scaling up GANs for Text-to-Image Synthesis (GigaGAN)](https://arxiv.org/abs/2303.05511)
* 03/2023: [LERF: Language Embedded Radiance Fields (LERF)](https://arxiv.org/abs/2303.09553v1)
* 04/2023: [Segment Anything (SAM)](https://arxiv.org/abs/2304.02643)

## Reinforcement Learning
* 01/2022: [Learning robust perceptive locomotion for quadrupedal robots in the wild (Robot Locomotion)](https://www.science.org/doi/abs/10.1126/scirobotics.abk2822)
* 01/2022: [Decision making of autonomous vehicles in lane change scenarios... (Safe AV)](https://www.sciencedirect.com/science/article/abs/pii/S0968090X21004411)
* 02/2022: [Accelerated Quality-Diversity through Massive Parallelism (QDax)](https://arxiv.org/abs/2202.01258)
* 02/2022: [Outracing champion Gran Turismo drivers with deep reinforcement learning (Gran Turismo)](https://www.nature.com/articles/s41586-021-04357-7)
* 02/2022: [Magnetic control of tokamak plasmas through deep reinforcement learning (Tokamak Control)](https://www.nature.com/articles/s41586-021-04301-9%E2%80%A6)
* 03/2022: [Model-Free Quantum Control with Reinforcement Learning (Quantum Control)](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.12.011059)
* 05/2022: [A Generalist Agent (Gato)](https://arxiv.org/abs/2205.06175)
* 06/2022: [MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge (MineDojo)](https://arxiv.org/abs/2206.08853)
* 08/2022: [Learning to Walk in Minutes Using Massively Parallel Deep Reinforcement Learning (ANYmal)](https://arxiv.org/abs/2109.11978)
* 10/2022: [Discovering faster matrix multiplication algorithms with reinforcement learning (AlphaTensor)](https://www.nature.com/articles/s41586-022%20-05172-4)
* 10/2022: [DeXtreme: Transfer of Agile In-hand Manipulation from Simulation to Reality (DeXtreme)](https://arxiv.org/abs/2210.13702)
* 11/2022: [Benchmarking Quality-Diversity Algorithms on Neuroevolution for Reinforcement Learning (QD-RL)](https://arxiv.org/abs/2211.02193)
* 01/2023: [Mastering Diverse Domains through World Models (DreamerV3)](https://arxiv.org/abs/2301.04104)
* 02/2023: [Grounding Large Language Models in Interactive Environments with Online RL (Grounding LLM)](https://arxiv.org/abs/2302.02662v1)
* 02/2023: [ManiSkill2: A Unified Benchmark for Generalizable Manipulation Skills (ManiSkill2)](https://arxiv.org/abs/2302.04659v1)
* 03/2023: [Reward Design with Language Models (RD-LLM)](https://arxiv.org/abs/2303.00001v1)
* 04/2023: [DiffMimic: Efficient Motion Mimicking with Differentiable Physics (DiffMimic)](https://arxiv.org/abs/2304.03274)

## Audio Processing
* 02/2022: [mSLAM: Massively multilingual joint pre-training for speech and text (mSLAM)](https://arxiv.org/abs/2202.01374)
* 04/2022: [MAESTRO: Matched Speech Text Representations through Modality Matching (MAESTRO)](https://arxiv.org/abs/2204.03409)
* 05/2022: [NaturalSpeech: End-to-End Text to Speech Synthesis with Human-Level Quality (NaturalSpeech)](https://arxiv.org/abs/2205.04421)
* 05/2022: [SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing (SpeechT5)](https://arxiv.org/abs/2110.07205)
* 06/2022: [WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing (WavLM)](https://ieeexplore.ieee.org/abstract/document/9814838)
* 09/2022: [AudioLM: a Language Modeling Approach to Audio Generation (AudioLM)](https://arxiv.org/abs/2209.03143)
* 10/2022: [High Fidelity Neural Audio Compression (EnCodec)](https://arxiv.org/abs/2210.13438)
* 12/2022: [Robust Speech Recognition via Large-Scale Weak Supervision (Whisper)](https://arxiv.org/abs/2212.04356)
* 01/2023: [Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers (VALL-E)](https://arxiv.org/abs/2301.02111)
* 01/2023: [MusicLM: Generating Music From Text (MusicLM)](https://arxiv.org/abs/2301.11325)
* 01/2023: [AudioLDM: Text-to-Audio Generation with Latent Diffusion Models (AudioLDM)](https://arxiv.org/abs/2301.12503)
* 04/2023: [AUDIT: Audio Editing by Following Instructions with Latent Diffusion Models (AUDIT)](https://arxiv.org/abs/2304.00830)

## Multimodal Learning
* 01/2022: [BLIP: Boostrapping Language-Image Pre-training for Unified Vision-Language... (BLIP)](https://proceedings.mlr.press/v162/li22n.html)
* 02/2022: [data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language (Data2vec)](https://proceedings.mlr.press/v162/baevski22a.html)
* 03/2022: [VL-Adapter: Parameter-Efficient Transfer Learning for Vision-and-Language Tasks (VL-Adapter)](https://arxiv.org/abs/2112.06825)
* 04/2022: [Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality (Winoground)](https://arxiv.org/abs/2204.03162)
* 04/2022: [Flamingo: a Visual Language Model for Few-Shot Learning (Flamingo)](https://arxiv.org/abs/2204.14198)
* 05/2022: [A Generalist Agent (Gato)](https://arxiv.org/abs/2205.06175)
* 05/2022: [CoCa: Contrastive Captioners are Image-Text Foundation Models (CoCa)](https://arxiv.org/abs/2205.01917)
* 05/2022: [VLMo: Unified Vision-Language Pre-Training with Mixture-of-Modality-Experts (VLMo)](https://arxiv.org/abs/2111.02358)
* 08/2022: [Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks (BEiT)](https://arxiv.org/abs/2208.10442v2)
* 09/2022: [PaLI: A Jointly-Scaled Multilingual Language-Image Model (PaLI)](https://arxiv.org/abs/2209.06794)
* 09/2022: [Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering (mCoT)](https://arxiv.org/abs/2209.09513)
* 11/2022: [EVA: Exploring the Limits of Masked Visual Representation Learning at Scale (EVA)](https://arxiv.org/abs/2211.07636)
* 12/2022: [InternVideo: General Video Foundation Models via Generative and Discriminative... (InternVideo)](https://arxiv.org/abs/2212.03191v2)
* 12/2022: [CLIPPO: Image-and-Language Understanding from Pixels Only (CLIPPO)](https://arxiv.org/abs/2212.08045)
* 02/2023: [Language Is Not All You Need: Aligning Perception with Language Models (Kosmos-1)](https://arxiv.org/abs/2302.14045v2)
* 03/2023: [Prismer: A Vision-Language Model with An Ensemble of Experts (Prismer)](https://arxiv.org/abs/2303.02506)
* 03/2023: [PaLM-E: An Embodied Multimodal Language Model (PaLM-E)](https://arxiv.org/abs/2303.03378)

## Other Papers
* 05/2022: [FlashAttention: Fast and Memory-Efficient Exact Attention with 10-Awareness (FlashAttention)](https://arxiv.org/abs/2205.14135)
* 05/2022: [ColabFold: making protein folding accessible to all (ColabFold)](https://www.nature.com/articles/s41592-022-01488-1)
* 02/2023: [Symbolic Discovery of Optimization Algorithms (Lion)](https://arxiv.org/abs/2302.06675)
